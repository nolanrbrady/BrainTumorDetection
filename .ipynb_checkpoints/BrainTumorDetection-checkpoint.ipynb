{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "beadd035-54d3-4da0-9873-af5fe40d24f1",
   "metadata": {},
   "source": [
    "### Brain Tumor Image Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8cdc334e-5c68-4301-861e-fe2d6a254e65",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-29 17:54:07.488808: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Packages for Image clustering\n",
    "from collections import defaultdict\n",
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Working with Images\n",
    "import os\n",
    "from os import listdir\n",
    "import skimage\n",
    "from skimage import data\n",
    "from skimage.io import imread, imshow\n",
    "\n",
    "# Keras Packages\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "from tensorflow.keras.applications.inception_v3 import preprocess_input\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from sklearn.cluster import KMeans\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import shutil\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "98a3b776-08ef-4f7b-9830-5b0e2faa1e3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-29 17:54:13.377797: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "  model = InceptionV3(weights='imagenet', include_top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bfbd1267-a892-4d70-ab33-d359abb8f771",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Sanity Check\n",
    "    img = image.load_img('./BrainTumorsData/no/N19.JPG', color_mode = 'grayscale')\n",
    "    # img.getdata()\n",
    "    img.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "06ca3067-7adf-4985-a9a6-f5952aa86af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_image_feature(path):\n",
    "    img = image.load_img(path, color_mode = 'grayscale')\n",
    "    x = img_to_array(img)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    x = preprocess_input(x)\n",
    "    feat = model.predict(x)\n",
    "    feat = feat.flatten()\n",
    "    return feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbabc0f9-e865-4aa9-a27d-fd88fc928bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_DIR = \"./BrainTumorsData/brain_tumor_dataset\"\n",
    "\n",
    "features = []\n",
    "image_names = []\n",
    "types = ['yes', 'no']\n",
    "        \n",
    "# Process Image Information\n",
    "for option in types:\n",
    "    for i in os.listdir(f'{DATASET_DIR}/{option}'):\n",
    "        # check if the image ends with png\n",
    "        if (i.endswith(\".jpg\")):\n",
    "            img_path = f'{DATASET_DIR}/{option}/{i}'\n",
    "            # Process Image\n",
    "            img = image.load_img(img_path, target_size=(224,224))\n",
    "            x = img_to_array(img)\n",
    "            x = np.expand_dims(x, axis=0)\n",
    "            x = preprocess_input(x)\n",
    "            feat = model.predict(x)\n",
    "            feat = feat.flatten()\n",
    "            # Push to storage array\n",
    "            features.append(feat)\n",
    "            image_names.append(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "037bf869-e285-48cc-bb9b-b6fb2baa9f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to Extract features from the images\n",
    "def image_feature(direc):\n",
    "    model = InceptionV3(weights='imagenet', classes=2)\n",
    "    features = [];\n",
    "    img_name = [];\n",
    "    for i in tqdm(os.listdir(direc)):\n",
    "        \n",
    "        img = image.load_img(i, target_size=(224,224))\n",
    "        x = img_to_array(img)\n",
    "        x = np.expand_dims(x,axis=0)\n",
    "        x = preprocess_input(x)\n",
    "        feat = model.predict(x)\n",
    "        feat = feat.flatten()\n",
    "        features.append(feat)\n",
    "        img_name.append(i)\n",
    "    return features,img_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5328c9ea-d70e-42eb-9b0a-695d8a1d8695",
   "metadata": {},
   "outputs": [],
   "source": [
    "# direc = './BrainTumorsData/brain_tumor_dataset/combined'\n",
    "# img_features, img_name = image_feature(direc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f287c9ea-1875-4e96-abc3-4d42342daf33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KMeans(n_clusters=2, random_state=50)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating Clusters\n",
    "k = 2\n",
    "clusters = KMeans(k, random_state=50)\n",
    "clusters.fit(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "987b3655-56cc-468b-823c-5f4cf365dfdd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>clusterid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Y6.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Y194.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Y180.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Y90.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Y47.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>N3.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>27 no.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>35 no.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>no 6.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>11 no.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>238 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         image  clusterid\n",
       "0       Y6.jpg          0\n",
       "1     Y194.jpg          0\n",
       "2     Y180.jpg          1\n",
       "3      Y90.jpg          1\n",
       "4      Y47.jpg          0\n",
       "..         ...        ...\n",
       "233     N3.jpg          1\n",
       "234  27 no.jpg          0\n",
       "235  35 no.jpg          1\n",
       "236   no 6.jpg          1\n",
       "237  11 no.jpg          0\n",
       "\n",
       "[238 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_cluster = pd.DataFrame(image_names, columns=['image'])\n",
    "image_cluster[\"clusterid\"] = clusters.labels_\n",
    "image_cluster # 0 denotes no tumor and 1 denotes tumor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8174b59f-55ee-44c9-8cb8-50717f858b7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50.84033613445378% accurate\n"
     ]
    }
   ],
   "source": [
    "# Determine Accuracy\n",
    "alignments = []\n",
    "for img in image_cluster.iterrows():\n",
    "    # print(img[1].clusterid)\n",
    "    name = img[1].image\n",
    "    cluster_id = img[1].clusterid\n",
    "    does_align = ('Y' in name and cluster_id == 1) or ('no' in name and cluster_id == 0)\n",
    "    # print(name, cluster_id, does_align)\n",
    "    alignments.append(does_align)\n",
    "    \n",
    "    \n",
    "accurate = alignments.count(True)\n",
    "print(f'{accurate/len(alignments) * 100}% accurate')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
